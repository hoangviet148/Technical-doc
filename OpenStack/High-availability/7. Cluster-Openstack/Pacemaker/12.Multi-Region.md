

## LAB Openstack Multi Region 

## 1 . Intro 
- The so-called openstack multi-region, is that multiple sets of openstack share a keystone and horizon. Each region has an openstack environment that can be distributed in different geographical locations, as long as the network is reachable. Personally, the purpose is to provide the function of environmental isolation. When you choose to start the virtual machine, you can choose according to your location.


## 2. Thông tin cụm 
### 2.1. Host Network trên 2  cụm

![](https://i.imgur.com/52nKVOx.png)


### 2.2. Phân bổ IP

- Cụm 1 :  Không  bổ sung cấu hình  tại các dịch vụ. Đã định danh Region1
![](https://i.imgur.com/GTupVrY.png)


- Cụm 2 . Cấu hình thêm Endpoint
![](https://i.imgur.com/dyrRzzM.png)



## 3. Cấu hình môi trường ban đầu

### 1. Trên các node tại cụm 2  ( CUM HCM )

- Cấu hình file host  
```
cat <<EOF > /etc/hosts
# controller 1
# controller 1
192.168.50.121       controller1
# controller 2
192.168.50.122       controller2
# controller 2
192.168.50.123       controller3
# compute 1
192.168.50.124       compute1
# compute 2
192.168.50.125       compute2
# cinder 1
192.168.50.126 storage1

# VIP
192.168.50.120  controllerhn

## VIP 

192.168.50.140       controllerhcm

EOF
```

### 2. Trên các node tại cụm 1 ( CUM HN )

```
cat <<EOF > /etc/hosts

# controller 1
192.168.50.131       controller1
# controller 2
192.168.50.132       controller2
# controller 3
192.168.50.133       controller3
# compute 1
192.168.50.134       compute1
# compute 2
192.168.50.135       compute2
# cinder 1
192.168.50.136      storage1

# VIP 
192.168.50.120  controllerhn

# VIP
192.168.50.140  controllerhcm


EOF
```


## 3 Cấu hình trên các Controller ở Cụm 1


-  Khởi tạo các Endpoint cho cụm 2 
	- Với endpoint keystone thì sẽ sử dụng VIP của cụm 1, đồng nghĩa với việc access chung database với cụm 1
	- Với các endpoint servce thì sẽ sử dụng VIP của cụm mới, các endpoint này được access qua API 
```

## Keystone  ## Share authencation with RegionOne
openstack endpoint create --region RegionHN keystone public http://controller:5000/v3/ 
openstack endpoint create --region RegionHN keystone internal http://controller:5000/v3/ 
openstack endpoint create --region RegionHN keystone admin http://controller:5000/v3/

## Glance
openstack endpoint create --region RegionHN image public http://controllerhn:9292
openstack endpoint create --region RegionHN image internal http://controllerhn:9292
openstack endpoint create --region RegionHN image admin http://controllerhn:9292

## Nova
openstack endpoint create --region RegionHN  compute public http://controllerhn:8774/v2.1
openstack endpoint create --region RegionHN  compute internal http://controllerhn:8774/v2.1
openstack endpoint create --region RegionHN  compute admin http://controllerhn:8774/v2.1

## Placement
openstack endpoint create --region RegionHN placement public http://controllerhn:8778
openstack endpoint create --region RegionHN placement internal http://controllerhn:8778
openstack endpoint create --region RegionHN placement admin http://controllerhn:8778

## Neutron 
openstack endpoint create --region RegionHN network public http://controllerhn:9696
openstack endpoint create --region RegionHN  network internal http://controllerhn:9696
openstack endpoint create --region RegionHN  network admin http://controllerhn:9696

## Cinder

openstack endpoint create --region RegionHN \
  volumev2 public http://controllerhn:8776/v2/%\(project_id\)s
openstack endpoint create --region RegionHN \
  volumev2 internal http://controllerhn:8776/v2/%\(project_id\)s
openstack endpoint create --region RegionHN \
  volumev2 admin http://controllerhn:8776/v2/%\(project_id\)s
openstack endpoint create --region RegionHN \
  volumev3 public http://controllerhn:8776/v3/%\(project_id\)s
openstack endpoint create --region RegionHN \
  volumev3 internal http://controllerhn:8776/v3/%\(project_id\)s
openstack endpoint create --region RegionHN \
  volumev3 admin http://controllerhn:8776/v3/%\(project_id\)s

```

- Cấu hình Horizon ` /etc/openstack-dashboard/local_settings.py`
```
AVAILABLE_REGIONS = [   
 ('http://192.168.50.129:5000/v3', 'RegionOne'),  
 ('http://192.168.50.140:5000/v3', 'RegionTwo'),  
]
```

##  4. Cấu hình trên các Controller ở Cụm 2

- Cấu hình bổ sung
```
[keystone_authtoken]
...
region_name = RegionHN
...

[nova], [neutron], [cinder]
...
region_name = RegionHN
...
```

- Cấu hình bổ sung
	- cấu hình authen : sử dụng cụm 1 để xác thực
	- cấu hình endpoint : sử dụng region_name để sử dụng endpoint 


- Gỡ cài đặt Keystone, bởi vì cụm 2 đang được share từ cụm 1
```
yum remove -y openstack-keystone
```

- Sử dụng Cụm 1 để xác thực, nên các auth_url và thông tin sẽ giống như trên cụm 1, bổ sung thêm cấu hình 
`region_name`


- Cấu hình glance-api 

```
cat <<EOF > /etc/glance/glance-api.conf 
[DEFAULT]
bind_host = `hostname -i`

[database]
connection = mysql+pymysql://glance:glance_123@controllerhn/glance

[keystone_authtoken]
www_authenticate_uri  = http://controllerhcm:5000
auth_url = http://controllerhcm:5000
memcached_servers = controller1:11211,controller2:11211,controller3:11211
auth_type = password
project_domain_name = Default
user_domain_name = Default
project_name = service
username = glance
password = glance_123
region_name = RegionHN


[paste_deploy]
flavor = keystone

[glance_store]
stores = file,http
default_store = file
filesystem_store_datadir = /var/lib/glance/images/

EOF
```


- Cấu hình Glance-Registry
```
cat <<EOF >  /etc/glance/glance-registry.conf

[DEFAULT]
bind_host = `hostname -i`

[database]

connection = mysql+pymysql://glance:glance_123@controllerhn/glance
connection_recycle_time = 3600

[keystone_authtoken]
www_authenticate_uri = http://controllerhcm:5000
auth_url = http://controllerhcm:5000
memcached_servers = controller1:11211,controller2:11211,controller3:11211
auth_type = password
project_domain_name = Default
user_domain_name = Default
project_name = service
username = glance
password = glance_123
region_name = RegionHN

[paste_deploy]

flavor = keystone

EOF

```

- Cấu hình Nova
```
cat <<EOF>  /etc/nova/nova.conf
[DEFAULT]

my_ip = `hostname -i`
osapi_compute_listen = \$my_ip
rpc_backend=rabbit
enabled_apis = osapi_compute,metadata
use_neutron = true
metadata_host = \$my_ip
metadata_listen = \$my_ip
firewall_driver = nova.virt.firewall.NoopFirewallDriver
transport_url=rabbit://openstack:rabbitmq_123@controller1,openstack:rabbitmq_123@controller2,openstack:rabbitmq_123@controller3
rpc_response_timeout = 180

[api_database]
connection = mysql+pymysql://nova:nova_123@controllerhn/nova_api

[database]
connection = mysql+pymysql://nova:nova_123@controllerhn/nova

[placement_database]
connection = mysql+pymysql://placement:placement_123@controllerhn/placement

[api]
auth_strategy = keystone

[keystone_authtoken]
auth_url = http://controllerhcm:5000/v3
memcached_servers = controller1:11211,controller2:11211,controller3:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = nova
password = nova_123
region_name = RegionHN


[vnc]
enabled = true
server_listen = 0.0.0.0
server_proxyclient_address = \$my_ip
novncproxy_host = \$my_ip

[glance]
api_servers = http://controllerhn:9292

[oslo_concurrency]
lock_path = /var/lib/nova/tmp

[placement]
region_name = RegionHN
project_domain_name = Default
project_name = service
auth_type = password
user_domain_name = Default
auth_url = http://controllerhcm:5000/v3
username = placement
password = placement_123

[oslo_messaging_rabbit]

rabbit_retry_interval=1
rabbit_retry_backoff=2
rabbit_max_retries=0
rabbit_ha_queues= true


[neutron]
url = http://controllerhn:9696 
#endpoint_override = http://controllerhn:9696
auth_url = http://controllerhcm:5000
auth_type = password
project_domain_name = default
user_domain_name = default
region_name = RegionHN
project_name = service
username = neutron
password = neutron_123
service_metadata_proxy = true
metadata_proxy_shared_secret = metadata_123

[cinder]
os_region_name = RegionHN



EOF
```


- Cấu hình Neutron
```
cat <<EOF> /etc/neutron/neutron.conf 

[DEFAULT]
transport_url=rabbit://openstack:rabbitmq_123@controller1,openstack:rabbitmq_123@controller2,openstack:rabbitmq_123@controller3
auth_strategy = keystone
core_plugin = ml2
dhcp_agents_per_network = 2 
notify_nova_on_port_status_changes = true
notify_nova_on_port_data_changes = true
bind_host = `hostname -i`
rpc_response_timeout = 180


[database]
connection = mysql+pymysql://neutron:neutron_123@controllerhn/neutron

[keystone_authtoken]

www_authenticate_uri = http://controllerhcm:5000
auth_url = http://controllerhcm:5000
memcached_servers = controller1:11211,controller2:11211,controller3:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = neutron
password = neutron_123
region_name = RegionHN


[nova]
auth_url = http://controllerhcm:5000
auth_type = password
project_domain_name = default
user_domain_name = default
region_name = RegionHN
project_name = service
username = nova
password = nova_123

[oslo_messaging_rabbit]
rabbit_retry_interval=1
rabbit_retry_backoff=2
rabbit_max_retries=0
rabbit_ha_queues= true

[oslo_concurrency]
lock_path = /var/lib/neutron/tmp

EOF
```


- Cấu hình  Cinder
```

cat <<EOF> /etc/cinder/cinder.conf
[DEFAULT]
my_ip = `hostname -i`
osapi_volume_listen = `hostname -i`
transport_url = rabbit://openstack:rabbitmq_123@controller1,openstack:rabbitmq_123@controller2,openstack:rabbitmq_123@controller3
auth_strategy = keystone
rpc_response_timeout = 180
enabled_backends = lvm
glance_api_servers = http://controllerhn:9292
state_path = /var/lib/cinder
log_dir = /var/log/cinder
debug = true

[database]
connection = mysql+pymysql://cinder:cinder_123@controllerhn/cinder

[keystone_authtoken]
auth_uri = http://controllerhcm:5000
auth_url = http://controllerhcm:5000
memcached_servers = controller1:11211,controller2:11211,controller3:11211
auth_type = password
project_domain_id = default
user_domain_id = default
project_name = service
username = cinder
password = cinder_123
region_name = RegionHN

[oslo_messaging_rabbit]

rabbit_retry_interval=1
rabbit_retry_backoff=2
rabbit_max_retries=0
rabbit_ha_queues= true

[oslo_concurrency]
lock_path = /var/lib/cinder/tmp


EOF
```


- Khoi dong dich vu
```
systemctl restart openstack-glance-api openstack-glance-registry
systemctl  status openstack-glance-api openstack-glance-registry
systemctl restart openstack-nova-api.service \
  openstack-nova-consoleauth openstack-nova-scheduler.service \
  openstack-nova-conductor.service openstack-nova-novncproxy.service
systemctl status openstack-nova-api.service \
  openstack-nova-consoleauth openstack-nova-scheduler.service \
  openstack-nova-conductor.service openstack-nova-novncproxy.service
systemctl restart neutron-server.service
systemctl status neutron-server.service 
systemctl restart openstack-cinder-api.service openstack-cinder-scheduler.service 
systemctl status openstack-cinder-api.service openstack-cinder-scheduler.service

```

##  4. Cấu hình trên các Compute ở Cụm 2


- Cấu hình Nova
```
cat <<EOF > /etc/nova/nova.conf
[DEFAULT]
my_ip = `hostname -i`
enabled_apis = osapi_compute,metadata
transport_url=rabbit://openstack:rabbitmq_123@controller1,openstack:rabbitmq_123@controller2,openstack:rabbitmq_123@controller3
use_neutron = true
firewall_driver = nova.virt.firewall.NoopFirewallDriver
rpc_response_timeout = 180

[api]
auth_strategy = keystone

[keystone_authtoken]
auth_url = http://controllerhcm:5000/v3
memcached_servers = controller1:11211,controller2:11211,controller3:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = nova
password = nova_123
region_name = RegionHN

[vnc]
enabled = true
server_listen = 0.0.0.0
server_proxyclient_address = \$my_ip
novncproxy_base_url = http://192.168.50.120:6080/vnc_auto.html

[glance]
api_servers = http://controllerhn:9292

[oslo_concurrency]
lock_path = /var/lib/nova/tmp

[placement]
region_name = RegionHN
project_domain_name = Default
project_name = service
auth_type = password
user_domain_name = Default
auth_url = http://controllerhcm:5000/v3
username = placement
password = placement_123

[oslo_messaging_rabbit]
rabbit_retry_interval=1
rabbit_retry_backoff=2
rabbit_max_retries=0
rabbit_ha_queues= true

[libvirt]
virt_type = kvm
hw_machine_type = x86_64=pc-i440fx-rhel7.2.0

[neutron]
url = http://controllerhn:9696 
#endpoint_override = http://controllerhn:9696
auth_url = http://controllerhcm:5000
auth_type = password
project_domain_name = default
user_domain_name = default
region_name = RegionHN
project_name = service
username = neutron
password = neutron_123

[cinder]
os_region_name = RegionHN

EOF
```



- Cấu hình Neutron
```
cat <<EOF> /etc/neutron/neutron.conf 

[DEFAULT]
transport_url = rabbit://openstack:rabbitmq_123@controller1,openstack:rabbitmq_123@controller2,openstack:rabbitmq_123@controller3
auth_strategy = keystone
rpc_response_timeout = 180


[keystone_authtoken]
www_authenticate_uri = http://controllerhcm:5000
auth_url = http://controllerhcm:5000
memcached_servers = controller1:11211,controller2:11211,controller3:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = neutron
password = neutron_123
region_name = RegionHN

[oslo_concurrency]
lock_path = /var/lib/neutron/tmp


[oslo_messaging_rabbit]
rabbit_retry_interval=1
rabbit_retry_backoff=2
rabbit_max_retries=0
rabbit_ha_queues= true


EOF
```

- Khởi động lại dịch vụ
```
systemctl restart openstack-nova-compute
systemctl status openstack-nova-compute
systemctl restart openstack-nova-compute.service
for service in 	dhcp-agent openvswitch-agent metadata-agent
do
systemctl enable neutron-$service
systemctl restart neutron-$service
systemctl status neutron-$service
done 

```

##  4. Cấu hình trên các Storage ở Cụm 2


- Cấu hình Cinder
```
cat <<EOF > /etc/cinder/cinder.conf
[DEFAULT]
transport_url=rabbit://openstack:rabbitmq_123@controller1,openstack:rabbitmq_123@controller2,openstack:rabbitmq_123@controller3
enabled_backends = lvm
glance_api_servers = http://controllerhn:9292
rpc_response_timeout = 180

[database]
auth_strategy = keystone
connection = mysql+pymysql://cinder:cinder_123@controllerhn/cinder

[keystone_authtoken]
www_authenticate_uri = http://controllerhcm:5000
auth_url = http://controllerhcm:5000
memcached_servers = controller1:11211,controller2:11211,controller3:11211
auth_type = password
project_domain_id = default
user_domain_id = default
project_name = service
username = cinder
password = cinder_123
region_name = RegionHN


[lvm]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_group = cinder-volumes
target_helper = lioadm
target_protocol = iscsi


[oslo_concurrency]
lock_path = /var/lib/cinder/tmp

EOF
```

- Khởi động lại dịch vụ


```
systemctl enable openstack-cinder-volume
systemctl restart openstack-cinder-volume
```

