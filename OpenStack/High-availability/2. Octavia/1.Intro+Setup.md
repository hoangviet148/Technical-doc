
## Cài đặt Octavia trên Openstack



## 1. Octavia - Load Balancing Solution For Openstack
### 1.1 . Mở đầu

- Octavia là project trong Openstack, được sử dụng làm giải pháp cân bằng tải trong Openstack. 
- Octavia được bắt đầu từ Neutron LBaas Project. 
- Octavia cung cấp dịch vụ cân bằng tải bằng  cách các máy ảo quản lý  máy ảo, container, bare metal server , được gọi chung là : _amphorae_. Octavia khác với khác với các giải khác vì nó sinh để phục vụ cho môi trường cloud, tùy chỉnh theo yêu cầu

### 1.2 : Octavia được sử dụng trong Openstack khi nào

- Cân bằng tải ( load balancing ) là điều cần thiết để để mở rộng quy mô có thể đơn giản hoặc quy mô lớn và tự động. 
- Octavia được xem là project cần thiết giống như Nova, Neutron và các core project khác - điều cần thiết để xây dựng một Openstack Cloud ecosystem
- Để hoàn thành vai trò , Octavia cần làm việc với các project khác :
	- Nova : để quản lý vòng đời các tài nguyên trên các compute node theo nhu cầu
	- Neutron : cho các mạng tentant ( project ) và các mạng external 
	- Barbican : quản lý TLS certificate và credential , và TLS Session
	- Keystone : dùng để xác thực Octavia API và làm việc với các project khác
	- Glance : để lưu trữ các _amphorae_ virtual image
	- Olso : để giai tiếp giữa các Octavia compoment.
	- Taskflow : 

- Octavia được thiết kế để tương tác với các thành phần ở trên. Với trên trừng project Octavia sẽ sử dụng một driver interface để làm việc.
- Kể từ phiên bản Pike, Octavia được sử dụng làm một giải pháp cân bằng tải độc lập. Neutron LBaas được xóa bỏ tại phiên bản Queens, Octavia sẽ được sử dụng thay thế. 


### 1.3 . Thành phần trong Octavia

![](https://img-blog.csdn.net/2018073009232644?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ptaWxr/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)


- Amphorea : là một máy ảo , container hoặc server cung cấp dịch vụ cân bằng tải. Nêu là máy ảo sẽ chạy trên các compute node, với các cấu hình để có khả năng cân bằng tải như listenner, pool, heath monitor, L7 Policies, hoặc gửi heat beat về Heah Manager
- Controller : được xem là "brain" của Octavia . Có bao gồm các thành phần con , và các tiến trình daemon. Nó có thể tương tác với các các thành phần con thông qua các drvier interface. 
	- API Controller : cung cấp API interface, nhận các request và gửi về controller worker thông qua Olso message
	- Controller worker : nhận các lệnh từ API controller, sau đó thực hiện các yêu đầu đề đề ra
	- Heath Manager : cung cấp khả năng heat beat tới các amphorea, kiểm tra trạng thái và cung cấp khăng failover cho các máy ảo này
	- Housekeeping Manager : cung cấp khả năng scaleup hoặc xóa dữ liệu và quản lý vòng đời của amphora certificate
- network : octavia không thể hoàn thành nếu thiếu network. Các máy ảo amphora được gắn một network interface từ Load Balance network,hoặc sẽ là một port trên các tentant network. 
- Pool : tập hợp các memeber lắng nghe request từ load balancer . Mỗi pool chỉ được liên kết với một listener.
![](https://access.redhat.com/webassets/avalon/d/Red_Hat_OpenStack_Platform-13-Networking_Guide-en-US/images/1c872c1cb32da36ce85f48656ad056d8/OpenStack_Networking-Guide_471659_0518_LBaaS-Topology.png)


## 2.2 : Các thuật ngữ bổ sung trong Octavia

- Fail-over là cho phép công việc thường chỉ được thực hiện bởi một máy chủ có thể thực hiện được bởi một máy chủ khác khi một trong 2 máy chủ xảy ra sự cố.
- Amphora Load Balancer Driver : được sử dụng bởi controlller để giao tiếp với amphorae. 
- Anchor : là một projec trong Openstack cung cấp các khóa PKI ngắn hạn. Octavia sử dụng cho việc authen giữa các compoment
- Apolocation : là các amphorae không được đặt lên cùng một host vật lý 
- L7 Policy : các tập policy cho quá trình routing cho các Client
- L7 Rule : các tập policy yêu cầu trùng khớp với các kết nối đến từ Client
- LB Network : network được controlller và amphorae giao tiếp , không được gán vào một project nào
- Listener : là các giao thức hoặc cổng ( không có IP )  sử dụng trong quá trình cân bằng tải
- VIP : Virtual IP Address : địa chỉ IP tĩnh được gắn cho quá trình cân bằng tải. Giống như các giao thức  CARP, VRRP, or HSRP sẽ có IP riêng cho quá trình định tuyến . Trong otavia , VIP sẽ được vào vào một network device định tuyến packet đến các máy ảo cân bằng tải và load cho các máy ảo backend

## 2.2  : Các mode triển khai trong Octavia

- Trong Octavia hiện tại với bản Queens đang gồm 2 mode : SINGEL và ACTIVE_BACKUP

- Đối với SINGEL : cung cấp khả năng cân bằng tải , không có khả năng Failover co cho các Load Blancer
- Đối với ACTIVE_STANDBY : cung cấp khả năng cân bằng tải , có khả năng Failover chLoad Blancer


## 3. Cài đặt Octavia mô hình SINGLE

- Cơ sở để cấu hình :
All API calls described throughout the rest of this document require authentication with the  [OpenStack Identity service](https://docs.openstack.org/keystone/latest/). After authentication, the base  `endpoint  URL`  for the  `service  type`  of  `load-balancer`  and  `service  name`  of  `octavia`  can be extracted from the service catalog returned with the identity token.
- https://docs.openstack.org/octavia/queens/contributor/guides/dev-quick-start.html
- URL : https://developer.openstack.org/api-ref/load-balancer/v2/index.html

- Yêu cầu :
	- Đã cài đặt các project : Keystone, Glance, Neutron ( bao gồm L3 Agent ) , Nova, Barbican

### 3.1. Cài đặt package

- Do cần sử dụng một số thư việc nên cần clone project của octavia
```
git clone https://github.com/openstack/octavia.git /root/octavia  -b stable/queens
```

- Khởi tạo  _Certificate_ Authorities sử dụng để mã hóa khi liên hệ giữa thành phần. Lưu ý đã bật service `Barbican`
```
bash /root/octavia/bin/create_certificates.sh /etc/octavia/certs/ /root/octavia/etc/certificates/openssl.cnf 
```

- Copy cau hinh DHCP
```
cp -R /root/octavia/etc/dhcp /etc/octavia/
chown -R root:octavia /etc/octavia
```

-  Cài đặt package ( kiểm tra kỹ trước khi cài đặt, có thể gây xung đột với các project khác ) 
```
wget https://pypi.python.org/packages/5e/5d/4e4364bb8b2a3e8d6c41ec21095aae3ac3396a6fa6983ea7f5551e929661/pyasn1-0.4.2-py2.4.egg#md5=84cf09817d8eb3b8955c5c558abd7ba7
easy_install pyasn1-0.4.2-py2.4.egg 
pip install pyasn1-modules==0.2.2
pip install Jinja2==2.10
pip install pyOpenSSL==17.1.0
yum install -y python-octavia openstack-octavia-common openstack-octavia-diskimage-create openstack-octavia-health-manager openstack-octavia-housekeeping openstack-octavia-ui openstack-octavia-worker openstack-octavia-amphora-agent python2-octaviaclient openstack-octavia-api 

```

- Khởi tạo Database cho Octavia
```
mysql -u root --password=hung <<EOF
CREATE DATABASE octavia;
GRANT ALL PRIVILEGES ON octavia.* TO 'octavia'@'localhost' \
IDENTIFIED BY 'octavia_123';
GRANT ALL PRIVILEGES ON octavia.* TO 'octavia'@'%' \
IDENTIFIED BY 'octavia_123';
EOF
```


### 3.2 . Khởi tạo User, Service ( sử dụng tài khoản admin )


- Khởi tạo User  và phân quyền
```
source admin-openrc
openstack user create --domain default --password octavia_123 octavia
openstack role add --project service --user octavia admin
openstack service create load-balancer --name octavia
```

- Khởi tạo Endpoint
```
openstack endpoint create octavia public http://controller:9876 --region RegionOne 
openstack endpoint create octavia admin http://controller:9876 --region RegionOne
openstack endpoint create octavia internal http://controller:9876 --region RegionOne
```


- Khởi tạo network và subnet   VIP
```
openstack network create --external --default --share --provider-physical-network provider   --provider-network-type flat provider
openstack subnet create --subnet-range 192.168.30.0/24 --dhcp --allocation-pool start=192.168.30.140,end=192.168.30.160 --dns-nameserver 1.1.1.1 --gateway=192.168.30.1 --network provider provider-net-30
```

- Khởi tạo file rc để đăng nhập vào user `octavia` , sử dụng để khởi tạo các Security group, Flavor, Key pair
```
cat <<EOF > octovia-openrc
export OS_PROJECT_DOMAIN_NAME=Default
export OS_USER_DOMAIN_NAME=Default
export OS_PROJECT_NAME=service
export OS_USERNAME=octavia
export OS_PASSWORD=octavia_123
export OS_AUTH_URL=http://controller:5000/v3
export OS_IDENTITY_API_VERSION=3
export OS_IMAGE_API_VERSION=2
EOF
```

### 3.2 . Khởi tạo Network, Security Group ( thực hiện trên Octavia User ) 

#### Các khởi tạo dưới đây được sử dụng cho section `controller_worker` trong tập tin cấu hình `/etc/octavia/octavia.conf`

- Đăng nhập vào user `octovia`
```
source octovia-openrc
```


- Khởi tạo  Security Group và Rule cho LB Network . 
( ID trả về : ce6fd5ce-de4c-43fe-927a-f2a1103a34bd ) 
```
openstack --os-region-name=RegionOne security group create lb-mgmt-sec-grp
openstack --os-region-name=RegionOne security group rule create --protocol icmp lb-mgmt-sec-grp
openstack --os-region-name=RegionOne security group rule create --protocol tcp --dst-port 22 lb-mgmt-sec-grp
openstack --os-region-name=RegionOne security group rule create --protocol tcp --dst-port 9443 lb-mgmt-sec-grp
openstack --os-region-name=RegionOne security group rule create --protocol icmpv6 --ethertype IPv6 --remote-ip ::/0 lb-mgmt-sec-grp
openstack --os-region-name=RegionOne security group rule create --protocol tcp --dst-port 22 --ethertype IPv6 --remote-ip ::/0 lb-mgmt-sec-grp
openstack --os-region-name=RegionOne security group rule create --protocol tcp --dst-port 9443 --ethertype IPv6 --remote-ip ::/0 lb-mgmt-sec-grp

```

 - Khởi tạo Security group cho Health manager  ( heatbeat tới các VM Load Balanacer ) . Đây là mạng liên hệ giữa Controller và các VM Load Balancer.  
```
openstack --os-region-name=RegionOne security group create lb-health-mgr-sec-grp
openstack --os-region-name=RegionOne security group rule create --protocol udp --dst-port 5555 lb-health-mgr-sec-grp
openstack --os-region-name=RegionOne security group rule create --protocol udp --dst-port 5555 --ethertype IPv6 --remote-ip ::/0 lb-health-mgr-sec-grp
```


- Khởi tạo LB Network ( ID trả về : 5cb04d80-c822-45dd-bd61-0d7fc1f2fcd0 ) 

```
neutron --os-region-name=RegionOne net-create lb-mgmt-net1
neutron --os-region-name=RegionOne subnet-create --name lb-mgmt-subnet1 lb-mgmt-net1 192.168.199.0/24 --no-gateway

```

- Khởi tạo port trên neutron sử dụng Security Group  `lb-health-mgr-sec-grp`, sau đó gắn vào openvswitch cho Health Manager ( thực hiện trên tất cả node controller  )
```
id_and_mac=$(neutron --os-region-name=RegionOne port-create --name octavia-health-manager-region-one-listen-port --security-group lb-health-mgr-sec-grp --device-owner Octavia:health-mgr --binding:host_id=$(hostname) lb-mgmt-net1 $PORT_FIXED_IP | awk '/ id | mac_address / {print $4}')
id_and_mac=($id_and_mac)
MGMT_PORT_ID=${id_and_mac[0]}
MGMT_PORT_MAC=${id_and_mac[1]}
MGMT_PORT_IP=$(openstack --os-region-name=RegionOne port show -f value -c fixed_ips $MGMT_PORT_ID | awk '{FS=",| "; gsub(",",""); gsub("'\''",""); for(i = 1; i <= NF; ++i) {if ($i ~ /^ip_address/) {n=index($i, "="); if (substr($i, n+1) ~ "\\.") print substr($i, n+1)}}}')
neutron --os-region-name=RegionOne port-update --binding:host_id=$(hostname) $MGMT_PORT_ID
sudo ovs-vsctl -- --may-exist add-port ${OVS_BRIDGE:-br-int} o-hm0 -- set Interface o-hm0 type=internal -- set Interface o-hm0 external-ids:iface-status=active -- set Interface o-hm0 external-ids:attached-mac=$MGMT_PORT_MAC -- set Interface o-hm0 external-ids:iface-id=$MGMT_PORT_ID -- set Interface o-hm0 external-ids:skip_cleanup=true
OCTAVIA_DHCLIENT_CONF=/etc/octavia/dhcp/dhclient.conf
sudo ip link set dev o-hm0 address $MGMT_PORT_MAC
sudo dhclient -v o-hm0 -cf $OCTAVIA_DHCLIENT_CONF

```


- Cấu hình FirewallD

```bash
firewall-cmd --add-port 5555/udp  --permanent
firewall-cmd --reload 
```


- Khởi tạo flavor cho Amphora ( ID Flavor trả về : 7c3a80ff-822e-4ace-bffb-54739c4a1108 )
```bash
openstack flavor create --disk 4 --ram 1024 --vcpus 1 --private --project service amphora_vm
```

- Khởi tạo và upload một image mới cho máy ảo Amphora ( đảm nhiệm là Load Balancer - ID trả về :6c7c0a18-fe65-4065-9a1e-4dc170f1659d, tag trả về :  amphora )
```
octavia-diskimage-create.sh -s 3 -r 123@123Aa -i centos -o centos-ha
openstack image create amphora-x64 --public --container-format bare --disk-format qcow2 --file /var/log/octavia/centos-ha.qcow2
openstack image set amphora-x64 --tag amphora-x64

```

### 3.2. Cấu hình Neutron


- Tham khảo thêm : https://docs.openstack.org/neutron/queens/admin/config-dns-int.html
- Cấu hình `/etc/neutron/neutron.conf`
```
[DEFAULT]
dns_domain = 1.1.1.1
[octavia]
base_url=http://127.0.0.1:9876
```

- Cấu hình ML2 `/etc/neutron/plugins/ml2/ml2_conf.ini`
```
[ml2]
extension_drivers = port_security,dns_domain_ports
```

- Khởi động lại dịch vụ
```
systemctl restart neutron-server
```

### 3.3. Cấu hình Octavia hoàn chỉnh




- Cấu hình tại `/etc/octavia/octavia.conf`
```
cat <<EOF> /etc/octavia/octavia.conf

[DEFAULT]
transport_url = rabbit://openstack:rabbitmq_123@controller
publish_errors = true
debug = False
use_syslog = True
 
[api_settings]

auth_strategy = keystone
bind_host = 0.0.0.0
bind_port = 9876
api_v1_enabled = true
api_v2_enabled = true
 
[database]

connection = mysql+pymysql://octavia:octavia_123@controller/octavia

[health_manager]
event_streamer_driver = noop_event_streamer
heartbeat_key = insecure
controller_ip_port_list = {IP at o-hm0 }:5555
bind_ip = {IP at o-hm0}
bind_port = 5555
sync_provisioning_status = true


[keystone_authtoken]

www_authenticate_uri = http://controller:5000/v3
auth_url = http://controller:35357/v3

username = octavia
password = octavia_123
project_name = service
project_domain_name = Default
user_domain_name = Default
auth_type = password
 
[certificates]
cert_manager = barbican_cert_manager
ca_certificate = /etc/octavia/certs/ca_01.pem
ca_private_key = /etc/octavia/certs/private/cakey.pem
ca_private_key_passphrase = foobar
 
[anchor]
[networking]

[haproxy_amphora]

bind_host = 0.0.0.0
bind_port = 9443
server_ca = /etc/octavia/certs/ca_01.pem
client_cert = /etc/octavia/certs/client.pem
base_path = /var/lib/octavia
base_cert_dir = /var/lib/octavia/certs
connection_max_retries = 1500
connection_retry_interval = 1
 
[controller_worker]

workers = 1
amp_active_retries = 100
amp_active_wait_sec = 5
loadbalancer_topology = SINGLE
amp_ssh_key_name = pair_LB
amp_image_tag = amphora-x64
amp_secgroup_list = 985491e0-f399-4584-8f4a-4a3aa737714e
amp_boot_network_list = 18a03d0a-8ad6-41e2-93ad-1abe8edce9b6
amp_flavor_id = 6c7c0a18-fe65-4065-9a1e-4dc170f1659d

network_driver = allowed_address_pairs_driver
compute_driver = compute_nova_driver
amphora_driver = amphora_haproxy_rest_driver

amp_image_id = 7e5d5455-178b-4830-87eb-8fc1f9aefe63

[task_flow]
 
[oslo_messaging]
rpc_thread_pool_size = 2
topic = octavia_prov

[oslo_messaging_rabbit]
rabbit_host = controller
rabbit_userid = openstack
rabbit_password = rabbitmq_123
 
[house_keeping]

load_balancer_expiry_age = 3600 

[amphora_agent]
[keepalived_vrrp]
 
[service_auth]
project_domain_name = Default
project_name = service
user_domain_name = Default
username = octavia
password = octavia_123
auth_type = password
auth_url = http://controller:35357/v3


[nova]
[cinder]
[glance]
[neutron]
[quotas]



```

- Đồng bộ database
```
chown octavia:octavia /etc/octavia/certs -R
octavia-db-manage upgrade head
```

- Khởi động dịch vụ
```
systemctl start octavia-api.service
systemctl start octavia-worker.service
systemctl start octavia-health-manager.service
systemctl start octavia-housekeeping.service

systemctl status octavia-api.service
systemctl status octavia-worker.service
systemctl status octavia-health-manager.service
systemctl status octavia-housekeeping.service


systemctl enable octavia-api.service
systemctl enable octavia-worker.service
systemctl enable octavia-health-manager.service
systemctl enable octavia-housekeeping.service

```


- Cấu hình FirwallD
```
firewall-cmd --add-port=9876/tcp --permanent 
firewall-cmd --reload
```

- Cài đặt  Octavia Dashboard
```
git clone https://github.com/openstack/octavia-dashboard.git  -b stable/queens
cd octavia-dashboard && python setup.py sdist
cp -a \
  `pwd`/octavia_dashboard/enabled/_1482_*.py \
  /usr/share/openstack-dashboard/openstack_dashboard/enabled/
cd /usr/share/openstack-dashboard/ 
./manage.py collectstatic 
./manage.py compress
systemctl restart httpd
```

 openstack loadbalancer create --name lb8 --vip-subnet-id f653162e-945d-495a-8a03-e29503eb429e --debug
 

## 4. Các note tham khảo


- Octavia makes use of an “LB Network” exclusively as a management network that the controller uses to talk to amphorae and vice versa. All the amphorae that Octavia deploys will have interfaces and IP addresses on this network. Therefore, it’s important that the subnet deployed on this network be sufficiently large to allow for the maximum number of amphorae and controllers likely to be deployed throughout the lifespan of the cloud installation.

At the present time, only IPv4 subnets have been tested as the LB Network (for example: 172.31.0.0/16), though there are plans to eventually support IPv6 subnets for the LB Network.

The LB Network is isolated from tenant networks on the amphorae by means of network namespaces on the amphorae. Therefore, operators need not be concerned about overlapping subnet ranges with tenant networks.

You must also create a Neutron security group which will be applied to amphorae created on the LB network. It needs to allow amphorae to send UDP heartbeat packets to the health monitor (by default, UDP port 5555), and ingress on the amphora’s API (by default, TCP port 9443). It can also be helpful to allow SSH access to the amphorae from the controller for troubleshooting purposes (ie. TCP port 22), though this is not strictly necessary in production environments.

Amphorae will send periodic health checks to the controller’s health manager. Any firewall protecting the interface on which the health manager listens must allow these packets from amphorae on the LB Network (by default, UDP port 5555).

Finally, you need to add routing or interfaces to this network such that the Octavia controller (which will be described below) is able to communicate with hosts on this network. This also implies you should have some idea where you’re going to run the Octavia controller components.

You must:

-   Create the ‘lb-mgmt-net’.
-   Assign the ‘lb-mgmt-net’ to the admin tenant.
-   Create a subnet and assign it to the ‘lb-mgmt-net’.
-   Create neutron security group for amphorae created on the ‘lb-mgmt-net’. which allows appropriate access to the amphorae.
-   Update firewall rules on the host running the octavia health manager to allow health check messages from amphorae.
-   Add appropriate routing to / from the ‘lb-mgmt-net’ such that egress is allowed, and the controller (to be created later) can talk to hosts on this network.





This spec introduces the Neutron QoS function to meet the requirements. Currently, there are 3 ports(at least) in the loadbalancer created by Octavia. One is from the lb-mgmt-net, the others are from the vip-subnet, called “loadbalancer-LOADBALANCER_ID” and “octavia-lb-vrrp-LOADBALNCER_ID”. The first one is vip port, the second one is for vrrp HA, and it will set “allowed_address_pairs” toward vip fixed_ip. The QoS policy should focus on the attached port “octavia-lb-vrrp-LOADBALNCER_ID”.

We could apply the Neutron QoS policy to the “octavia-lb-vrrp-LOADBALNCER_ID” ports, whether the topology is active-active or standalone.

## 5. Tham khảo thêm
- https://github.com/openstack/octavia/blob/master/devstack/plugin.sh
- http://blog.51cto.com/superbigsea/1862253
- http://gogosatellite.blogspot.com/2016/08/study-openstack-octavia-in-mitaka-by.html
- https://blog.csdn.net/Jmilk/article/details/81279795
- https://docs.openstack.org/tricircle/queens/install/installation-guide.html
- https://blog.zufardhiyaulhaq.com/manual-instalation-octavia-openstack-queens/
- https://lingxiankong.github.io/2017-09-13-octavia.html
- https://blog.csdn.net/Jmilk/article/details/81279795
- https://medium.com/@sankasathyaji/octavia-loadbalancer-installation-on-openstack-7ad19eea38dd
- https://ask.openstack.org/en/question/94127/mitakaoctavia-octavia-worker-cannot-reach-amphora/
- https://medium.com/@sankasathyaji/octavia-loadbalancer-installation-on-openstack-7ad19eea38dd
- https://docs.mirantis.com/mcp/latest/mcp-deployment-guide/configure-octavia.html
- https://www.codetd.com/article/4530901
- https://docs.openstack.org/octavia/latest/reference/glossary.html
- https://docs.openstack.org/octavia/queens/configuration/configref.html
- https://docs.openstack.org/mitaka/networking-guide/config-lbaas.html
- https://docs.openstack.org/newton/networking-guide/config-lbaas.html
- https://docs.openstack.org/octavia/queens/contributor/guides/dev-quick-start.html
- https://docs.openstack.org/openstack-ansible-os_octavia/latest/configure-octavia.html
- https://docs.openstack.org/tricircle/rocky/install/installation-guide.html
